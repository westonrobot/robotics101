{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font color=green>OpenCV Basics Sample Codes</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=Red> About </font></h2>\n",
    "\n",
    "This notebook seeks to cover and demonstrate certain topics of basic OpenCV. While this notebook covers most of what you would need in a basic computer vision project, the concepts covered here are non-exhaustive. OpenCV is an open source library that provides a commmon infrastructure for computer vision applications and to accelerate the use of machine perception in commercial products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's an image?\n",
    "\n",
    "An image is an ordered collection of square pixels arranged in columns and rows. A pixel is the smallest unit of a digital image that can be displayed and represented on a digital display device.\n",
    "\n",
    "![pixel](assets/pixel.jpg)\n",
    "\n",
    "In order to understand how computer’s “see” we first need a fundamental understanding of what an image is. \n",
    "\n",
    "<img src=\"assets/rgb_channel.png\" width=\"500\">\n",
    "\n",
    "On the left is the original image. When a computer scans, stores, or retrieves this image, it will first break it down into three separate channels: red , green, and blue. This is commonly known as RGB.\n",
    "Red, green, and blue are used as they can be combined in various proportions to obtain any color in the visible spectrum.\n",
    "\n",
    "#### How do computers see?\n",
    "\n",
    "The answer is they don't. At least not in the way we humans do. Computers only understand data in the form of numbers. These numbers are often stored in arrays and matrices. An array is a collection of items stored at contiguous memory locations. The idea is to store multiple items of the **same data type** together.\n",
    "\n",
    "We just went over how a computer breaks an image down into three channels. After this is done, these channels are then converted into a three-dimensional array. Look at the image below for a graphical representation of a 3-dimensional array.\n",
    "\n",
    "<img src=\"assets/3d_array.png\" width=\"500\">  \n",
    "*Note: the values in this example have been standardized so that the values are on a scale of 0 to 1.  \n",
    "\n",
    "Each cell of the array, corresponds to a pixel in the image. This means that the array’s dimensions are equal to the resolution of the image. Therefore, a color image with a resolution of 1920 x 1080 pixels will be broken down to a 3d array with 1920 rows and 1080 columns. The values stored in each cell of the array represent the intensity (brightness) of that channel for the corresponding pixel.\n",
    "\n",
    "### Representing images\n",
    "\n",
    "Digital images can be represented in an array of data types **uint8**, **uint16**, **uint32**. These data types determine the memory size allocated for each cell in the array (8 bit, 16 bit, 32 bit).\n",
    "  \n",
    "When an image is represented in an array of data type uint8, each cell in the array can be assigned a value that ranges from 0 to 255 (2<sup>8</sup>). What this means is that each pixel can be represented by 255 different shades of red, green and blue, amounting to more than 16 million colour permutations. \n",
    "Likewise, if the image is represented in an array of data type uint16, each cell in the array can be assigned a value that ranges from 0 to 65535 (2<sup>16</sup>), where 0 being no light and 65535 being the brightest.\n",
    "\n",
    "The intensity which is represented by the values depepnds on the data type of the image array, where 0 being no light while 255 and 65535 being the brightest for 8 bit and 16 bit respectively. For example, the colour magenta in 8 bit RGB is (255, 0, 255). The brightness of the colour can be reduced by decreasing the values of the red and blue channel equally.   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing images in OpenCV\n",
    "\n",
    "Images can be represented in several different colour spaces, one of them being RGB. Color spaces are a way to represent the pixels present in the image that gives the image that particular hue. There are several different color spaces and each has its own significance. Some of the popular color spaces are RGB (Red, Green, Blue), CMYK (Cyan, Magenta, Yellow, Black), HSV (Hue, Saturation, Value), etc. **BGR color space**: OpenCV’s default color space is RGB. However, it actually stores color in the BGR format. \n",
    "\n",
    "#### RGB colour space\n",
    "![RGB](assets/colour_diagram.png)\n",
    "\n",
    "#### CYMK colour space\n",
    "<img src=\"assets/cymk.png\" width=\"500\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy arrays\n",
    "\n",
    "Numpy is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and numerous functions for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, etc.\n",
    "\n",
    "NumPy’s array class is called ndarray. This encapsulates n-dimensional arrays of homogeneous data types, with many operations being performed. OpenCV for Python treats image data as ndarray.\n",
    "\n",
    "For those of you who may be wondering why not use python lists instead, there are several important differences between NumPy arrays and the standard Python sequences:\n",
    "\n",
    "* NumPy arrays have a fixed size at creation, unlike Python lists (which can grow dynamically). Changing the size of an ndarray will create a new array and delete the original.\n",
    "\n",
    "* The elements in a NumPy array are all required to be of the **same data type**, and thus will be the same size in memory. \n",
    "\n",
    "* NumPy arrays facilitate advanced mathematical and other types of operations on large numbers of data such as high resolution images and videos. Typically, such operations are executed more efficiently and with less code than is possible using Python’s built-in sequences.\n",
    "\n",
    "* An increasing amount scientific and mathematical Python-based packages are using NumPy arrays; though these typically support Python-sequence input, they convert such input to NumPy arrays prior to processing, and they often output NumPy arrays. In other words, in order to efficiently use most of today’s scientific/mathematical Python-based software, just knowing how to use Python’s built-in sequence types is insufficient - one also needs to know how to use NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array creation\n",
    "\n",
    "When you use numpy.array to define a new array, you should consider the dtype of the elements in the array, which can be specified explicitly. This feature gives you more control over the underlying data structures and how the elements are handled.\n",
    "* a list of numbers will create a 1D array,\n",
    "\n",
    "* a list of lists will create a 2D array,\n",
    "\n",
    "* further nested lists will create higher-dimensional arrays. In general, any array object is called an ndarray in NumPy.\n",
    "\n",
    "* The function *zeros* creates an array full of zeros, the function *ones* creates an array full of ones, and the function *empty* creates an array whose initial content is random. The zeros function can be particularly useful in OpenCV to create a 3d array filled with zeroes (black image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# One dimensional array of type uint8\n",
    "onedim_arr = np.array([1, 2, 3], dtype=np.int8)\n",
    "print(onedim_arr)\n",
    "\n",
    "# Two dimensional array of type uint8\n",
    "twodim_arr = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int8)  \n",
    "print(twodim_arr)\n",
    "\n",
    "# NumPy arange() is one of the array creation routines based on the numerical range specified.\n",
    "# Numpy will create an array with elements ranging from 0 to 14.\n",
    "# The reshape function specifies the dimensions of the array created. (3, 5) represents 3 nested arrays with 5 elementsd each.\n",
    "arr = np.arange(15).reshape(3, 5)\n",
    "print(arr)\n",
    "\n",
    "\n",
    "# Three dimensional array of zeroes\n",
    "zero_arr = np.zeros((3,3, 3), dtype=np.int8)\n",
    "print(zero_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes of an array\n",
    "\n",
    "* ndarray.ndim\n",
    "    * the number of axes (rows) of the array.\n",
    "\n",
    "* ndarray.shape\n",
    "    * the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with n rows and m columns, shape will be (n,m). The length of the shape tuple is therefore the number of axes, ndim.\n",
    "\n",
    "* ndarray.size\n",
    "    * the total number of elements of the array. This is equal to the product of the elements of shape.\n",
    "\n",
    "* ndarray.dtype\n",
    "    * an object describing the type of the elements in the array. One can create or specify dtype’s using standard Python types. Additionally NumPy provides types of its own. numpy.int32, numpy.int16, and numpy.float64 are some examples.\n",
    "\n",
    "* ndarray.itemsize\n",
    "    * the size in bytes of each element of the array. For example, an array of elements of type float64 has itemsize 8 (=64/8), while one of type complex32 has itemsize 4 (=32/8). It is equivalent to ndarray.dtype.itemsize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr.dtype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr.itemsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the basics covered, lets move into OpenCV proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read an Image\n",
    "  \n",
    "To read an image using the OpenCV library in python, we will need to these libraries:\n",
    "\n",
    "* Numpy Library : The computer processes images in the form of a matrix for which NumPy is used and  OpenCV uses it in the background.\n",
    "\n",
    "* OpenCV python : OpenCV library previously it was cv but the updated version is cv2. It is used to manipulate images and videos.\n",
    "\n",
    "To read the images **cv2.imread()** function is used.\n",
    "* Syntax: cv2.imread(path, flag)\n",
    "\n",
    "* Parameters:\n",
    "    * path: A string representing the path of the image to be read.\n",
    "\n",
    "    * flag: It specifies the way in which image should be read. It’s default value is cv2.IMREAD_COLOR  \n",
    "        * cv.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag. Can be replaced with integer value 1.\n",
    "        * cv.IMREAD_GRAYSCALE : Loads image in grayscale mode. Can be replaced with integer value 0.\n",
    "        * cv.IMREAD_UNCHANGED : Loads image as such including alpha channel. Can be replaced with integer value -1.  \n",
    "\n",
    "* Return Value: This method returns an image array that is loaded from the specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in colour\n",
    "img = cv2.imread('assets/puppy.jpg',1)\n",
    "\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)\n",
    "(h, w, d) = img.shape\n",
    "print(\"width={}, height={}, depth={}\".format(w, h, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an Image\n",
    "\n",
    "Use the function **cv.imshow()** to display an image in a window. The window automatically fits to the image size.\n",
    "* Syntax: cv2.imshow(name, image)\n",
    "\n",
    "* Parameters:\n",
    "    * name: A string representing the window name.\n",
    "\n",
    "    * image: It specifies the variable where the image array is stored.\n",
    "\n",
    "You can create as many windows as you wish, but with different window names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('puppy', img)\n",
    "\n",
    "# Porgram will hold the screen until user closes it.\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# It is for removing/deleting created GUI window from screen and memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv.waitKey()** is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes. \n",
    "\n",
    "Besides binding keyboard events this function also processes many other GUI events, so you MUST use it to actually display the image.\n",
    "\n",
    "**cv.destroyAllWindows()** simply destroys all the windows created. If you want to destroy any specific window, use the function **cv.destroyWindow()** where you pass the exact window name as the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write an Image\n",
    "Use the function **cv.imwrite()** to save an image to the directory of your choice.\n",
    "* Syntax: cv2.imwrite(path/filename, image)\n",
    "\n",
    "* Parameters:\n",
    "    * path/filename: A string representing the path to save the image and the name of the saved file.\n",
    "\n",
    "    * image: It specifies the variable where the image array is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image in grayscale\n",
    "img1 = cv2.imread('assets/puppy.jpg', 0)\n",
    "\n",
    "#save the image as .png\n",
    "cv2.imwrite('assets/puppy_grey.png', img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example to sum it all up\n",
    "\n",
    "Unicode table: https://unicode-table.com/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Image\n",
    "img2 = cv2.imread('assets/ace.jpg', 1)\n",
    "\n",
    "# Display Image\n",
    "cv2.imshow('puppy', img)\n",
    "cv2.imshow('card', img2)\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "if (key == ord('s')):   # 's' key\n",
    "\n",
    "    # Using keybinding to save the image\n",
    "    cv2.imwrite('card.png',img2)\n",
    "    cv2.destroyWindow()\n",
    "\n",
    "elif (key == 27):       # Esc key\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing functions in OpenCV\n",
    "\n",
    "You will learn these functions : **cv.line( )**, **cv.circle( )**, **cv.rectangle( )**, **cv.ellipse( )**, **cv.putText( )** etc.\n",
    "\n",
    "In all the above functions, you will see some common arguments as given below:\n",
    "\n",
    "* img : The image where you want to draw the shapes\n",
    "* color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.\n",
    "* thickness : Thickness of the line or circle etc. If **-1** is passed for closed figures like circles, it will fill the shape. default thickness = 1\n",
    "* lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv.LINE_AA gives anti-aliased line which looks great for curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing line\n",
    "\n",
    "To draw a line, you need to pass starting and ending coordinates of line. We will create a black image and draw a blue line on it from top-left to bottom-right corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image\n",
    "img3 = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "# Draw a diagonal blue line with thickness of 5 px\n",
    "\n",
    "cv2.line(img3,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "## write the neccessary code here to display the image ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing rectangle\n",
    "\n",
    "To draw a rectangle, you need top-left corner and bottom-right corner of rectangle. This time we will draw a green rectangle at the top-right corner of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img3,(384,0),(510,128),(0,255,0),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Circle\n",
    "\n",
    "To draw a circle, you need its center coordinates and radius. We will draw a circle with center (256,256), radius 100, colour BGR(120,120,0) and thickness 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img3,(256,256), 100, (120,120,0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing polygon\n",
    "\n",
    "To draw a polygon, first you need coordinates of vertices. Make those points into an array of shape ROWSx1x2 where ROWS are number of vertices and it should be of type int32. Here we draw a small polygon of with five vertices in yellow color.\n",
    "\n",
    "We can reshape any array into any shape as long as the elements required for reshaping are equal in both shapes. You are allowed to have one “unknown” dimension. What that means is that you don’t have to specify an example number for one of the dimensions in the reshape method. In such a case, pass -1 as the value (Eg: pts = pts.reshape(-1, 1, 2)) and NumPy will calculate this number for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array([[100,150],[250,350],[200,20],[50,10], [40,400]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img3,[pts],True,(0,255,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping images in OpenCV\n",
    "\n",
    "Extracting “regions of interest” (ROIs) is an important skill for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ROI (Region of Interest) from the\n",
    "# input image starting at x=290,y=60 at ending at x=520,y=380\n",
    "roi = img[60:380, 290:520]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing images in OpenCV\n",
    "\n",
    "Resizing images is important for a number of reasons. First, you might want to resize a large image to fit on your screen. Image processing is also faster on smaller images because there are fewer pixels to process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to 300x300px, ignoring aspect ratio\n",
    "resized = cv2.resize(img, (300, 300))\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the height and width of the image\n",
    "(h,w,d) = img.shape\n",
    "\n",
    "# fixed resizing and distort aspect ratio so let's resize the width\n",
    "# to be 300px but compute the new height based on the aspect ratio\n",
    "r = 300.0 / w\n",
    "dim = (300, int(h * r))\n",
    "resized = cv2.resize(img, dim)\n",
    "cv2.imshow(\"Aspect Ratio Resize\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing and Feature Detection\n",
    "\n",
    "In the next few sections we’ll learn how to use create a simple Python + OpenCV script to count the number of Tetris blocks in the following image:\n",
    "\n",
    "![tetris](assets/tetris_blocks.jpg)\n",
    "\n",
    "Along the way we’ll be:\n",
    "\n",
    "* Learning how to convert images to grayscale with OpenCV\n",
    "* Performing edge detection\n",
    "* Thresholding a grayscale image\n",
    "* Finding, counting, and drawing contours\n",
    "* Conducting erosion and dilation\n",
    "* Masking an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting an image to grayscale\n",
    "\n",
    "There are more than 150 color-space conversion methods available in OpenCV. But today we will look into only one which is widely used, **BGR to Gray**.\n",
    "\n",
    "For color conversion, we use the function **cv2.cvtColor(input_image, flag)** where flag determines the type of conversion. \n",
    "For BGR to Gray conversion we use the flag **cv2.COLOR_BGR2GRAY**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image (whose path was supplied via command line\n",
    "# argument) and display the image to our screen\n",
    "img4 = cv2.imread('assets/tetris_blocks.jpg')\n",
    "cv2.imshow(\"Image\", img4)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Edge detection is useful for finding boundaries of objects in an image — it is effective for segmentation purposes.\n",
    "\n",
    "Using the popular Canny algorithm (developed by John F. Canny in 1986), we can find the edges in the image.\n",
    "\n",
    "We provide three parameters to the **cv2.Canny** function:\n",
    "\n",
    "* img : The gray image.\n",
    "* minVal : A minimum threshold, in our case 30 .\n",
    "* maxVal : The maximum threshold which is 150 in our example.\n",
    "* aperture_size : The Sobel kernel size. By default this value is 3 and hence not included explicitly in the arguments\n",
    "\n",
    "* *Note*: More about thresholds in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying edge detection we can find the outlines of objects in images\n",
    "edged = cv2.Canny(gray, 30, 150)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding \n",
    "\n",
    "Thresholding is the assignment of pixel values in relation to the threshold value provided. In thresholding, each pixel value is compared with the threshold value. Thresholding is a very popular segmentation technique, used for separating an object considered as a foreground from its background.\n",
    "\n",
    "For this example, we will be thresholding our image using the THRESH_BINARY_INV flag. This will ensure that the foreground (tetris blocks) will be white and the background will be black.\n",
    "\n",
    "            If f (x, y) < T \n",
    "            then f (x, y) = 255 \n",
    "            else \n",
    "            f (x, y) = 0\n",
    "\n",
    "            where \n",
    "            f (x, y) = Coordinate Pixel Value\n",
    "            T = Threshold Value.\n",
    "\n",
    "We will use a threshold value of 225. This value was determined using trial and error. Feel free to experiment with different thresold values.\n",
    "\n",
    "OpenCV provides different types of thresholding. The simple thresholding types are:\n",
    "\n",
    "* cv.THRESH_BINARY\n",
    "* cv.THRESH_BINARY_INV\n",
    "* cv.THRESH_TRUNC\n",
    "* cv.THRESH_TOZERO\n",
    "* cv.THRESH_TOZERO_INV\n",
    "\n",
    "To know more about the different types of thresholding, refer to the [documentation](https://docs.opencv.org/4.1.1/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576a19120b1a11d8067576cc24f4d2f03754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "\n",
    "val, thresh1 = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Thresh1\", thresh1)\n",
    "\n",
    "val,thresh2 = cv2.threshold(gray,225,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow(\"Thresh2\", thresh2)\n",
    "\n",
    "val,thresh3 = cv2.threshold(gray,225,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow(\"Thresh3\", thresh3)\n",
    "\n",
    "val,thresh4 = cv2.threshold(gray,225,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow(\"Thresh4\", thresh4)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting contours\n",
    "\n",
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
    "\n",
    "In OpenCV, finding contours is like finding white objects from black background. So remember, object to be found should be white and background should be black. This was why we used the THRESH_BINARY_INV flag.\n",
    "\n",
    "To identify the contours, we will use the **cv2.findContours()** function. There are 3 arguments that need to be specified:\n",
    "* source image (usually a binary image for greater accuracy)\n",
    "* contour retrieval mode\n",
    "* contour approximation method\n",
    "\n",
    "Returns 3 arrays which are the image array, contour array and hierarchy array. \n",
    "\n",
    "#### Hierarchy\n",
    "\n",
    "When working with nested figures (Eg shapes within shapes), we call outer one as parent and inner one as child. This way, contours in an image has some relationship to each other. And we can specify how one contour is connected to each other, like, is it the child of some other contour, or is it a parent etc. Representation of this relationship is called the **Hierarchy**.\n",
    "\n",
    "### Drawing contours\n",
    "\n",
    "To draw the contours, **cv.drawContours** function is used. It can also be used to draw any shape provided you have its boundary points. \n",
    "* First argument is source image \n",
    "* Second argument is the contours which should be passed as a Python list \n",
    "* Third argument is index of contours (useful when drawing individual contours. To draw all contours, pass -1) \n",
    "* Remaining arguments are color, thickness etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour retrieval modes\n",
    "\n",
    "There are 4 different modes of contour retrieval algorithms.\n",
    "| Modes  | Description  |\n",
    "| -------------- | ------------ |\n",
    "| RETR_EXTERNAL | Retrieves only the extreme outer contours. All child contours are left behind. |\n",
    "| RETR_LIST | It simply retrieves all the contours, but doesn't create any parent-child relationship. |\n",
    "| RETR_CCOMP | Retrieves all the contours and arranges them to a 2-level hierarchy. External contours of the object (ie its boundary) are placed in hierarchy-1, while contours of holes inside object (if any) is placed in hierarchy-2. |\n",
    "| RETR_TREE | It retrieves all the contours and creates a full family hierarchy list. |\n",
    "\n",
    "For this example, since there are no nested shapes, we will use the **RETR_EXTERNAL** retrieval mode.\n",
    "\n",
    "For a more detailed explanation, refer to [documentation](https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour approximation method\n",
    "\n",
    "It has been established that contours are the boundaries of a shape with same intensity. It stores the (x,y) coordinates of the boundary of a shape. But does it need to store all the coordinates?  \n",
    "That is specified by this contour approximation method.\n",
    "\n",
    "If you pass cv.CHAIN_APPROX_NONE, all the boundary points are stored. \n",
    "For eg, you found the contour of a straight line. Do you need all the points on the line to represent that line? No, we need just two end points of that line. This is what cv.CHAIN_APPROX_SIMPLE does. It removes all redundant points and compresses the contour, thereby saving memory.\n",
    "\n",
    "Since our tetris blocks are made up of straight lines, we will use the **CHAIN_APPROX_SIMPLE** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the thresholded image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# draw all the contours on the output image with a 3px thick outline\n",
    "cv2.drawContours(img4, contours, -1, (200,200,140), 3)\n",
    "cv2.imshow('detected', img4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking an image\n",
    "\n",
    "We learnt earlier about isolating regions of interest(ROI) by cropping an image. We can also use masking to construct ROIs that are of arbitrary shape. \n",
    "\n",
    "Masking involves understanding what the *bitwise_and()* operation does.\n",
    "It computes the bitwise conjunction of two arrays (dst = src1 & src2). Calculates the per-element bit-wise conjunction of the two arrays.\n",
    "\n",
    "Parameters\n",
    "* src1 -\tfirst input array or a scalar.\n",
    "\n",
    "* src2 - \tsecond input array or a scalar.\n",
    "\n",
    "* dst  - \toutput array that has the same size and type as the input arrays.\n",
    "\n",
    "* mask - \toptional operation mask, 8-bit single channel array, that specifies elements of the output array to be changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a square of zeros using a variable\n",
    "rectangle = np.zeros((300, 300), dtype=\"uint8\")\n",
    "cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\n",
    "cv2.imshow(\"Rectangle : \", rectangle)\n",
    " \n",
    "# creating a circle of zeros using a variable\n",
    "circle = np.zeros((300, 300), dtype=\"uint8\")\n",
    "cv2.circle(circle, (150, 150), 150, 255, -1)\n",
    "cv2.imshow(\"Circle : \", circle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AND truth table\n",
    "\n",
    "| rectangle     | circle     | result |\n",
    "| -----| ------|----- |\n",
    "| 0     | 0     | 0     |\n",
    "| 0     | 1     | 0     |\n",
    "| 1     | 0     | 0     |\n",
    "| 1     | 1     | 1     |\n",
    "\n",
    "With reference to the truth table above, the white pixels represent 1 (True) and the black pixels represent 0 (False).  \n",
    "Note that both images need to be of the same size for the bitwise_and operation to work.  \n",
    "When we use the bitwise_and operation on images rectangle and circle:\n",
    "* the corresponding pixels that are white on both images will remain white\n",
    "* the corresponding pixels that are black on both images will remain black\n",
    "* The corresponding pixels that have a colour mismatch (1 AND 0) will result in black.\n",
    "\n",
    "Before executing the next code block, try to visualise the resultant image of the bitwise_and operation and see if you got it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bitwise_and function executes the AND operation\n",
    "# on both the images\n",
    "result = cv2.bitwise_and(rectangle, circle)\n",
    "cv2.imshow(\"result\", result)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a better idea of what the bitwise_and operation does, what is masking?  \n",
    "Masks allow us to “mask out” regions of an image we are uninterested in. We call them “masks” because they will hide regions of images we do not care about.  \n",
    "Lets create a circular mask that will isolate the puppy's face in the image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a 2-dimensional zero matrix the exact size of the puppy.jpg image\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "# Using a circular mask to isolate the face of the puppy. \n",
    "# Given that the puppy can be isolated if we draw a circle of radius 120px at center (405, 170).\n",
    "# The thickness argument can be omitted as we are filling the whole circle white this time.\n",
    "mask = cv2.circle(mask,(405,170), 120, (255,255,255), cv2.FILLED)\n",
    "\n",
    "# execute the bitwise 'AND' operation.\n",
    "roi = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imshow('puppy', img)\n",
    "cv2.imshow('roi', roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important part of this function is the **mask** keyword. When the masking matrix is provided, the *bitwise_and* function is True when both\n",
    "* the pixel values of the input images are equal and\n",
    "* the mask is non-zero at each (x, y)-pixel coordinate (in this case, only pixels that are part of the white circle)\n",
    "\n",
    "Though not applicable to this example, there are also other bitwise operations provided by OpenCV.\n",
    "* bitwise_not()\n",
    "    1. Inverts every bit of an array.\n",
    "    2. Parameters\n",
    "        * src -\tinput array.\n",
    "        * dst -\toutput array that has the same size and type as the input array.\n",
    "        * mask -\toptional operation mask, 8-bit single channel array, that specifies elements of the output array to be changed.  \n",
    "        \n",
    "* bitwise_or()\n",
    "    1. Calculates the per-element bit-wise disjunction of two arrays.\n",
    "    2. Parameters\n",
    "        * src1 -\tfirst input array or a scalar.\n",
    "        * src2 -\tsecond input array or a scalar.\n",
    "        * dst -\toutput array that has the same size and type as the input arrays.\n",
    "        * mask -\toptional operation mask, 8-bit single channel array, that specifies elements of the output array to be changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more practical example, lets isolate the blue tetris block in the image used above.\n",
    "\n",
    "To achieve this we will need to use the inRange() function. The inRange() function checks if array elements lie between the elements of the two, lowerb and upperb, arrays.  \n",
    "The arrays, lowerb and upperb, will define the limits of the blue shades to check for.\n",
    "\n",
    "Parameters\n",
    "* src - \tfirst input array.\n",
    "\n",
    "* lowerb - \tinclusive lower boundary array or a scalar.\n",
    "\n",
    "* upperb - \tinclusive upper boundary array or a scalar.\n",
    "\n",
    "* dst - \toutput array of the same size as src and CV_8U type.\n",
    "\n",
    "For every element of a single-channel input array:\n",
    "*   dst(I) = lowerb(I)<sub>0</sub> ≤ src(I)<sub>0</sub> ≤ upperb(I)<sub>0</sub>\n",
    "\n",
    "Since ours is a 3-channel input array:\n",
    "*    dst(I) = lowerb(I)<sub>0</sub> ≤ src(I)<sub>0</sub> ≤ upperb(I)<sub>0</sub> ∧ lowerb(I)<sub>1</sub> ≤ src(I)<sub>1</sub> ≤ upperb(I)<sub>1</sub> ∧ lowerb(I)<sub>2</sub> ≤ src(I)<sub>2</sub> ≤ upperb(I)<sub>2</sub>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original tetris image\n",
    "cv2.imshow('original',img4)\n",
    "\n",
    "# define the lower and upper values of BGR,\n",
    "# this will detect blue colour in the image\n",
    "blue_upper = np.array([255,100,100])    # Brighter shade of blue\n",
    "blue_lower = np.array([150,0,0])        # Darker shade of blue\n",
    "\n",
    "\n",
    "blue_mask = cv2.inRange(img4, blue_lower, blue_upper)\n",
    "cv2.imshow('mask',blue_mask)\n",
    "blue_img = cv2.bitwise_and(img4,img4,mask=blue_mask)\n",
    "cv2.imshow('blue',blue_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have covered the basics of OpenCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

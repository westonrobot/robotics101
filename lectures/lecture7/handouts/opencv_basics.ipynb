{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font color=green>OpenCV Basics Sample Codes</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=Red> About </font></h2>\n",
    "\n",
    "This notebook seeks to cover and demonstrate certain topics of basic OpenCV. While this notebook covers most of what you would need in a basic computer vision project, the concepts covered here are non-exhaustive. OpenCV is an open source library that provides a commmon infrastructure for computer vision applications and to accelerate the use of machine perception in commercial products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read an Image\n",
    "  \n",
    "To read an image using the OpenCV library in python, we will need to these libraries:\n",
    "\n",
    "* Numpy Library : The computer processes images in the form of a matrix for which NumPy is used and  OpenCV uses it in the background.\n",
    "\n",
    "* OpenCV python : OpenCV library previously it was cv but the updated version is cv2. It is used to manipulate images and videos.\n",
    "\n",
    "To read the images **cv2.imread()** function is used.\n",
    "* Syntax: cv2.imread(path, flag)\n",
    "\n",
    "* Parameters:\n",
    "    * path: A string representing the path of the image to be read.\n",
    "\n",
    "    * flag: It specifies the way in which image should be read. It’s default value is cv2.IMREAD_COLOR  \n",
    "        * cv.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag. Can be replaced with integer value 1.\n",
    "        * cv.IMREAD_GRAYSCALE : Loads image in grayscale mode. Can be replaced with integer value 0.\n",
    "        * cv.IMREAD_UNCHANGED : Loads image as such including alpha channel. Can be replaced with integer value -1.  \n",
    "\n",
    "* Return Value: This method returns an image array that is loaded from the specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in colour\n",
    "img = cv2.imread('assets/puppy.jpg',1)\n",
    "\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)\n",
    "(h, w, d) = img.shape\n",
    "print(\"width={}, height={}, depth={}\".format(w, h, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an Image\n",
    "\n",
    "Use the function **cv.imshow()** to display an image in a window. The window automatically fits to the image size.\n",
    "* Syntax: cv2.imshow(name, image)\n",
    "\n",
    "* Parameters:\n",
    "    * name: A string representing the window name.\n",
    "\n",
    "    * image: It specifies the variable where the image array is stored.\n",
    "\n",
    "You can create as many windows as you wish, but with different window names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('puppy', img)\n",
    "\n",
    "# Porgram will hold the screen until user closes it.\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# It is for removing/deleting created GUI window from screen and memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv.waitKey()** is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes. \n",
    "\n",
    "Besides binding keyboard events this function also processes many other GUI events, so you MUST use it to actually display the image.\n",
    "\n",
    "**cv.destroyAllWindows()** simply destroys all the windows created. If you want to destroy any specific window, use the function **cv.destroyWindow()** where you pass the exact window name as the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write an Image\n",
    "Use the function **cv.imwrite()** to save an image to the directory of your choice.\n",
    "* Syntax: cv2.imwrite(path/filename, image)\n",
    "\n",
    "* Parameters:\n",
    "    * path/filename: A string representing the path to save the image and the name of the saved file.\n",
    "\n",
    "    * image: It specifies the variable where the image array is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image in grayscale\n",
    "img1 = cv2.imread('assets/puppy.jpg', 0)\n",
    "\n",
    "#save the image as .png\n",
    "cv2.imwrite('assets/puppy_grey.png', img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example to sum it all up\n",
    "\n",
    "Unicode table: https://unicode-table.com/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Image\n",
    "img2 = cv2.imread('assets/ace.jpg', 1)\n",
    "\n",
    "# Display Image\n",
    "cv2.imshow('puppy', img)\n",
    "cv2.imshow('card', img2)\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "if (key == ord('s')):   # 's' key\n",
    "\n",
    "    # Using keybinding to save the image\n",
    "    cv2.imwrite('card.png',img2)\n",
    "    cv2.destroyWindow()\n",
    "\n",
    "elif (key == 27):       # Esc key\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing functions in OpenCV\n",
    "\n",
    "You will learn these functions : **cv.line( )**, **cv.circle( )**, **cv.rectangle( )**, **cv.ellipse( )**, **cv.putText( )** etc.\n",
    "\n",
    "In all the above functions, you will see some common arguments as given below:\n",
    "\n",
    "* img : The image where you want to draw the shapes\n",
    "* color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.\n",
    "* thickness : Thickness of the line or circle etc. If **-1** is passed for closed figures like circles, it will fill the shape. default thickness = 1\n",
    "* lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv.LINE_AA gives anti-aliased line which looks great for curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing line\n",
    "\n",
    "To draw a line, you need to pass starting and ending coordinates of line. We will create a black image and draw a blue line on it from top-left to bottom-right corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image\n",
    "img3 = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "# Draw a diagonal blue line with thickness of 5 px\n",
    "\n",
    "cv2.line(img3,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "## write the neccessary code here to display the image ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing rectangle\n",
    "\n",
    "To draw a rectangle, you need top-left corner and bottom-right corner of rectangle. This time we will draw a green rectangle at the top-right corner of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img3,(384,0),(510,128),(0,255,0),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Circle\n",
    "\n",
    "To draw a circle, you need its center coordinates and radius. We will draw a circle with center (256,256), radius 100, colour BGR(120,120,0) and thickness 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img3,(256,256), 100, (120,120,0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing polygon\n",
    "\n",
    "To draw a polygon, first you need coordinates of vertices. Make those points into an array of shape ROWSx1x2 where ROWS are number of vertices and it should be of type int32. Here we draw a small polygon of with five vertices in yellow color.\n",
    "\n",
    "We can reshape any array into any shape as long as the elements required for reshaping are equal in both shapes. You are allowed to have one “unknown” dimension. What that means is that you don’t have to specify an example number for one of the dimensions in the reshape method. In such a case, pass -1 as the value (Eg: pts = pts.reshape(-1, 1, 2)) and NumPy will calculate this number for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array([[100,150],[250,350],[200,20],[50,10], [40,400]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img3,[pts],True,(0,255,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping images in OpenCV\n",
    "\n",
    "Extracting “regions of interest” (ROIs) is an important skill for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ROI (Region of Interest) from the\n",
    "# input image starting at x=290,y=60 at ending at x=520,y=380\n",
    "roi = img[60:380, 290:520]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing images in OpenCV\n",
    "\n",
    "Resizing images is important for a number of reasons. First, you might want to resize a large image to fit on your screen. Image processing is also faster on smaller images because there are fewer pixels to process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to 300x300px, ignoring aspect ratio\n",
    "resized = cv2.resize(img, (300, 300))\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the height and width of the image\n",
    "(h,w,d) = img.shape\n",
    "\n",
    "# fixed resizing and distort aspect ratio so let's resize the width\n",
    "# to be 300px but compute the new height based on the aspect ratio\n",
    "r = 300.0 / w\n",
    "dim = (300, int(h * r))\n",
    "resized = cv2.resize(img, dim)\n",
    "cv2.imshow(\"Aspect Ratio Resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing and Feature Detection\n",
    "\n",
    "In the next few sections we’ll learn how to use create a simple Python + OpenCV script to count the number of Tetris blocks in the following image:\n",
    "\n",
    "![tetris](assets/tetris_blocks.jpg)\n",
    "\n",
    "Along the way we’ll be:\n",
    "\n",
    "* Learning how to convert images to grayscale with OpenCV\n",
    "* Performing edge detection\n",
    "* Thresholding a grayscale image\n",
    "* Finding, counting, and drawing contours\n",
    "* Conducting erosion and dilation\n",
    "* Masking an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour spaces in OpenCV\n",
    "\n",
    "Color spaces are a way to represent the pixels present in the image that gives the image that particular hue. There are several different color spaces and each has its own significance. Some of the popular color spaces are RGB (Red, Green, Blue), CMYK (Cyan, Magenta, Yellow, Black), HSV (Hue, Saturation, Value), etc. **BGR color space**: OpenCV’s default color space is RGB. However, it actually stores color in the BGR format. It is an additive color model where the different intensities of blue, green and red give different shades of colour.\n",
    "\n",
    "#### Converting an image to grayscale\n",
    "There are more than 150 color-space conversion methods available in OpenCV. But today we will look into only one which is widely used, **BGR to Gray**.\n",
    "\n",
    "For color conversion, we use the function **cv2.cvtColor(input_image, flag)** where flag determines the type of conversion. \n",
    "For BGR to Gray conversion we use the flag **cv2.COLOR_BGR2GRAY**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image (whose path was supplied via command line\n",
    "# argument) and display the image to our screen\n",
    "img4 = cv2.imread('assets/tetris_blocks.jpg')\n",
    "cv2.imshow(\"Image\", img4)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Edge detection is useful for finding boundaries of objects in an image — it is effective for segmentation purposes.\n",
    "\n",
    "Using the popular Canny algorithm (developed by John F. Canny in 1986), we can find the edges in the image.\n",
    "\n",
    "We provide three parameters to the **cv2.Canny** function:\n",
    "\n",
    "* img : The gray image.\n",
    "* minVal : A minimum threshold, in our case 30 .\n",
    "* maxVal : The maximum threshold which is 150 in our example.\n",
    "* aperture_size : The Sobel kernel size. By default this value is 3 and hence not included explicitly in the arguments\n",
    "\n",
    "* *Note*: More about thresholds in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying edge detection we can find the outlines of objects in images\n",
    "edged = cv2.Canny(gray, 30, 150)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding \n",
    "\n",
    "Thresholding is the assignment of pixel values in relation to the threshold value provided. In thresholding, each pixel value is compared with the threshold value. Thresholding is a very popular segmentation technique, used for separating an object considered as a foreground from its background.\n",
    "\n",
    "For this example, we will be thresholding our image using the THRESH_BINARY_INV flag. This will ensure that the foreground (tetris blocks) will be white and the background will be black.\n",
    "\n",
    "            If f (x, y) < T \n",
    "            then f (x, y) = 255 \n",
    "            else \n",
    "            f (x, y) = 0\n",
    "\n",
    "            where \n",
    "            f (x, y) = Coordinate Pixel Value\n",
    "            T = Threshold Value.\n",
    "\n",
    "We will use a threshold value of 225. This value was determined using trial and error. Feel free to experiment with different thresold values.\n",
    "\n",
    "OpenCV provides different types of thresholding. The simple thresholding types are:\n",
    "\n",
    "* cv.THRESH_BINARY\n",
    "* cv.THRESH_BINARY_INV\n",
    "* cv.THRESH_TRUNC\n",
    "* cv.THRESH_TOZERO\n",
    "* cv.THRESH_TOZERO_INV\n",
    "\n",
    "To know more about the different types of thresholding, refer to the [documentation](https://docs.opencv.org/4.1.1/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576a19120b1a11d8067576cc24f4d2f03754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "\n",
    "val, thresh1 = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Thresh1\", thresh1)\n",
    "\n",
    "val,thresh2 = cv2.threshold(gray,225,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow(\"Thresh2\", thresh2)\n",
    "\n",
    "val,thresh3 = cv2.threshold(gray,225,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow(\"Thresh3\", thresh3)\n",
    "\n",
    "val,thresh4 = cv2.threshold(gray,225,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow(\"Thresh4\", thresh4)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting contours\n",
    "\n",
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
    "\n",
    "In OpenCV, finding contours is like finding white objects from black background. So remember, object to be found should be white and background should be black. This was why we used the THRESH_BINARY_INV flag.\n",
    "\n",
    "To identify the contours, we will use the **cv2.findContours()** function. There are 3 arguments that need to be specified:\n",
    "* source image (usually a binary image for greater accuracy)\n",
    "* contour retrieval mode\n",
    "* contour approximation method\n",
    "\n",
    "Returns 3 arrays which are the image array, contour array and hierarchy array. \n",
    "\n",
    "#### Hierarchy\n",
    "\n",
    "When working with nested figures (Eg shapes within shapes), we call outer one as parent and inner one as child. This way, contours in an image has some relationship to each other. And we can specify how one contour is connected to each other, like, is it the child of some other contour, or is it a parent etc. Representation of this relationship is called the **Hierarchy**.\n",
    "\n",
    "### Drawing contours\n",
    "\n",
    "To draw the contours, **cv.drawContours** function is used. It can also be used to draw any shape provided you have its boundary points. \n",
    "* First argument is source image \n",
    "* Second argument is the contours which should be passed as a Python list \n",
    "* Third argument is index of contours (useful when drawing individual contours. To draw all contours, pass -1) \n",
    "* Remaining arguments are color, thickness etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour retrieval modes\n",
    "\n",
    "There are 4 different modes of contour retrieval algorithms.\n",
    "| Modes  | Description  |\n",
    "| -------------- | ------------ |\n",
    "| RETR_EXTERNAL | Retrieves only the extreme outer contours. All child contours are left behind. |\n",
    "| RETR_LIST | It simply retrieves all the contours, but doesn't create any parent-child relationship. |\n",
    "| RETR_CCOMP | Retrieves all the contours and arranges them to a 2-level hierarchy. External contours of the object (ie its boundary) are placed in hierarchy-1, while contours of holes inside object (if any) is placed in hierarchy-2. |\n",
    "| RETR_TREE | It retrieves all the contours and creates a full family hierarchy list. |\n",
    "\n",
    "For this example, since there are no nested shapes, we will use the **RETR_EXTERNAL** retrieval mode.\n",
    "\n",
    "For a more detailed explanation, refer to [documentation](https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour approximation method\n",
    "\n",
    "It has been established that contours are the boundaries of a shape with same intensity. It stores the (x,y) coordinates of the boundary of a shape. But does it need to store all the coordinates?  \n",
    "That is specified by this contour approximation method.\n",
    "\n",
    "If you pass cv.CHAIN_APPROX_NONE, all the boundary points are stored. \n",
    "For eg, you found the contour of a straight line. Do you need all the points on the line to represent that line? No, we need just two end points of that line. This is what cv.CHAIN_APPROX_SIMPLE does. It removes all redundant points and compresses the contour, thereby saving memory.\n",
    "\n",
    "Since our tetris blocks are made up of straight lines, we will use the **CHAIN_APPROX_SIMPLE** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the thresholded image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# draw all the contours on the output image with a 3px thick outline\n",
    "cv2.drawContours(img4, contours, -1, (200,200,140), 3)\n",
    "cv2.imshow('detected', img4)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! With that you have learnt the basics of OpenCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
